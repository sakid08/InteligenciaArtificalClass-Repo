# ğŸ” Estudio de DesempeÃ±o en Modelos Compactos de Inteligencia Artificial

## PropÃ³sito del Ejercicio

Esta actividad tuvo como finalidad analizar las competencias de 5 sistemas de IA de escala reducida (phi3:mini, gemma:2b, tinydolphin, tinyllama, qwen:0.5b) para interpretar y generar respuestas a interrogantes concretas derivadas de un programa acadÃ©mico de educaciÃ³n superior (Materia: Inteligencia Artificial, CÃ³digo: SCC-1012).

La valoraciÃ³n se enfocÃ³ en tres dimensiones principales: **exactitud de contenido**, **cumplimiento de directrices** y **consistencia lÃ³gica** en las salidas proporcionadas.

---

## Cuadro Resumen de Resultados

Para facilitar una revisiÃ³n visual expedita del comportamiento en cada Ã­tem, se adoptÃ³ un esquema de colores semafÃ³ricos.

| Modelo | P1 (PropÃ³sito) | P2 (Algoritmo A*) | P3 (Inferencia) | P4 (SBR) | P5 (Usos) | Resultado Final |
| :--- | :---: | :---: | :---: | :---: | :---: | :--- |
| **phi3:mini** | ğŸŸ¢ | ğŸŸ¢ | ğŸŸ¢ | ğŸŸ¡ | ğŸŸ¢ | **DesempeÃ±o Sobresaliente** |
| **gemma:2b** | ğŸŸ¡ | ğŸŸ¡ | ğŸ”´ | ğŸ”´ | ğŸŸ¢ | **Resultados HeterogÃ©neos** |
| **tinyllama** | ğŸŸ¡ | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | **Falla Severa (Alucinaciones)** |
| **tinydolphin** | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | **Falla Severa (Estructura)** |
| **qwen:0.5b** | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | ğŸ”´ | **Falla Severa (Sin Respuesta)** |

**Significado de los colores:**
* ğŸŸ¢ **Verde:** Respuesta ajustada al contexto y precisa segÃºn el contenido temÃ¡tico.
* ğŸŸ¡ **Amarillo:** Respuesta aceptable en parte, imprecisa o demasiado general.
* ğŸ”´ **Rojo:** Respuesta errÃ³nea, con invenciones (alucinaciones), o ausencia de respuesta pertinente.

---

## EvaluaciÃ³n Pormenorizada por Sistema

### ğŸ¥‡ Mejor DesempeÃ±o Global: phi3:mini

Este modelo evidenciÃ³ una habilidad notable para incorporar el marco de referencia del programa y contestar con adecuaciÃ³n.

* **P1 (PropÃ³sito):** InterpretÃ³ de manera integral la finalidad del curso ("formar al profesional", "modelado matemÃ¡tico", "soluciÃ³n de problemas complejos").
* **P2 (A*):** OfreciÃ³ la definiciÃ³n mÃ¡s completa, incorporando nociones de "bÃºsqueda", "trayectoria", "heurÃ­stica" y "reducciÃ³n de coste".
* **P3 (Inferencia):** DiferenciÃ³ acertadamente: la inferencia no monÃ³tona admite que las conclusiones se modifiquen ante datos novedosos.
* **P4 (SBR):** ReconociÃ³ los elementos principales ("base de conocimiento" y "reglas"), si bien no citÃ³ explÃ­citamente el "mecanismo de control".
* **P5 (Usos):** EnumerÃ³ las 6 aplicaciones esperadas y las complementÃ³ con breves explicaciones (a pesar de ciertos errores de escritura).

---

### ğŸ¥ˆ Resultados Desiguales: gemma:2b

Este sistema completÃ³ adecuadamente ciertas actividades sencillas de recuperaciÃ³n de informaciÃ³n, pero mostrÃ³ limitaciones en la explicaciÃ³n de nociones abstractas.

* **P1 (PropÃ³sito):** ProporcionÃ³ una respuesta vÃ¡lida pero genÃ©rica, menos adaptada al programa que `phi3`.
* **P2 (A*):** ExplicaciÃ³n demasiado breve ("hallar las rutas mÃ¡s cortas"). Aunque correcta, careciÃ³ de la profundidad esperada en un contexto universitario.
* **P3 y P4 (Inferencia y SBR):** Sus respuestas fueron imprecisas y conceptualmente equivocadas (por ejemplo, asociar "mÃºltiples lÃ³gicas" a la inferencia no monÃ³tona).
* **P5 (Usos):** **Logro completo**. ListÃ³ las 6 aplicaciones de manera clara y exacta.

---

### âŒ Falla Grave (Alucinaciones): tinyllama

Este modelo no solo errÃ³ en sus respuestas, sino que **generÃ³ informaciÃ³n ficticia** (alucinÃ³) ajena por completo al contenido del programa.

* **P2 (A*):** Error significativo. DescribiÃ³ A* como una tÃ©cnica para "configuraciÃ³n de ventanas" y lo mezclÃ³ con conceptos de inferencia no monÃ³tona.
* **P3 (Inferencia):** OmitiÃ³ por completo la pregunta.
* **P4 (SBR):** AlucinaciÃ³n notable. CreÃ³ una nociÃ³n de "siete sÃ­mbolos" y la vinculÃ³ con "HTML" y "sitios web".
* **P5 (Usos):** MencionÃ³ 6 Ã­tems, pero *ninguno* coincidÃ­a con la lista del Tema 4. GenerÃ³ una enumeraciÃ³n inventada.


---

### Falla Grave tinydolphin y qwen:0.5b

Ambos sistemas fracasaron en el requisito mÃ¡s elemental: seguir la instrucciÃ³n de "responder las 5 preguntas".

* **tinydolphin:** No contestÃ³ las preguntas. En su lugar, produjo un resumen del programa, pero lo hizo de manera incorrecta, combinando contenidos de distintos temas (ejemplo: ubicÃ³ "reglas y bÃºsqueda" en el Tema 2, correspondiente al Tema 3).
* **qwen:0.5b:** No generÃ³ respuestas. Simplemente repitiÃ³ las preguntas y, ademÃ¡s, asignÃ³ de modo errÃ³neo los nÃºmeros de los temas (por ejemplo, indicÃ³ que A* correspondÃ­a al Tema 2).

**SÃ­ntesis:** Estos modelos no lograron procesar la consigna (Preguntas + Contexto) y no superaron la evaluaciÃ³n.

---

## ğŸ“Œ Reflexiones Finales del Ejercicio

1.  **La Disparidad entre Modelos es Notable:** No todos los sistemas "compactos" poseen las mismas capacidades. `phi3:mini` mostrÃ³ habilidades de razonamiento contextual que lo sitÃºan muy por encima del resto.
2.  **AlucinaciÃ³n versus Ambiguidad:** Resulta mÃ¡s sencillo identificar un modelo "deficiente" (como `tinyllama`) que inventa respuestas incongruentes, que uno "mediocre" (como `gemma:2b`) que ofrece salidas vagas pero aparentemente vÃ¡lidas.